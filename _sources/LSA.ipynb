{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topik Modelling dengan Jupyter Notebook dengan menggunakan metode LSA (Latent Semantic Analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Berikut langkah - langkah yang harus dilakukan : <br>\n",
    "1 Pre-Processing. <br> Pada tahap ini ada 3 proses, yaitu: </br>\n",
    "    <ul>\n",
    "        <li> Pengecekan Missing Value\n",
    "        <li> Melakukan Stopword\n",
    "        <li> Melakukan Proses TF-IDF \n",
    "    </ul>\n",
    "2 Penerapan Model LSA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data preprocessing adalah proses awal untuk mengubah data mentah menjadi data yang lebih efisien dan siap untuk diproses di langkah selanjutnya. Proses ini dilakukan karena data mentah sering kali mengalami error, missing value, dan tidak konsisten. Maka dari itu Pre-Processing data dilakukan agar hasilnya tepat dan akurat. Dengan begitu, data tersebut dapat dilakukan untuk proses selanjutnya yaitu analisis data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <li> Pengecekan Missing Value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Missing Value merupakan hilangnya beberapa data yang di peroleh. Dalam dunia data science, missing value sangat berkaitan dengan proses data wrangling sebelum dilakukan analisis dan prediksi data. Data wrangling merupakan kegiatan penyeragaman data atau pembersihan data (cleaning data) dari data kotor (mentah) menjadi data yang nantinya siap digunakan untuk analisis. Data kotor (mentah) yang dimaksud adalah data yang terindikasi masih terdapat ketidakseragaman format, muncul missing values pada data, dan masih juga ditemukan adanya tambahan sufiks, prefiks dan lain-lain. <br><br>\n",
    "berikut merupakan proses pengidentifikasian missing value :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Import modul yang dibutuhkan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> read data yang akan digunakan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Judul</th>\n",
       "      <th>Mahasiswa</th>\n",
       "      <th>Dosbing_1</th>\n",
       "      <th>Dosbing_2</th>\n",
       "      <th>Abstrak_indo</th>\n",
       "      <th>Abstract_english</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Analisis Inovasi Dan Keunggulan Bersaing \\r\\nD...</td>\n",
       "      <td>Penulis : Sandy Ardiansyah</td>\n",
       "      <td>Dosen Pembimbing I : Dr. Ir. Nurita Andriani, MM.</td>\n",
       "      <td>Dosen Pembimbing II :Suyono, S.E., M. S. M.</td>\n",
       "      <td>ABSTRAK\\r\\n\\tTujuan penelitian ini adalah mend...</td>\n",
       "      <td>ABSTRACT\\r\\nThe purpose of this study is to de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pengaruh Bauran Pemasaran Terhadap Keputusan P...</td>\n",
       "      <td>Penulis : Mahrus Saleh</td>\n",
       "      <td>Dosen Pembimbing I : Dr.H Pribanus Wantara, Dr...</td>\n",
       "      <td>Dosen Pembimbing II :Hadi Purnomo, SE., MM</td>\n",
       "      <td>Objek penelitian ini adalah pembelian produk X...</td>\n",
       "      <td>Object this research is consumer product of XL...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ANALISIS PORTOFOLIO YANG OPTIMAL DI BEI DENGAN...</td>\n",
       "      <td>Penulis : Mira Dwiastuti</td>\n",
       "      <td>Dosen Pembimbing I : Hj Evaliati Amaniyah, S.E...</td>\n",
       "      <td>Dosen Pembimbing II :Echsan Gani, S.E, M.Si</td>\n",
       "      <td>Suatu keputusan investasi selalu berhubungan d...</td>\n",
       "      <td>An investment decision is always associated wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PENGARUH KOMPETENSI DOSEN TERHADAP KINERJA DOS...</td>\n",
       "      <td>Penulis : Aththaariq</td>\n",
       "      <td>Dosen Pembimbing I : Dr.RM Moch Wispandono,.S....</td>\n",
       "      <td>Dosen Pembimbing II :Dr. Muhammad Alkirom Wild...</td>\n",
       "      <td>Abstrak\\r\\n\\r\\nAththaariq, Pengaruh Kompetensi...</td>\n",
       "      <td>Abstract\\r\\n\\r\\nThis study is aimed to analyze...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PENGARUH FAKTOR-FAKTOR PELATIHAN DAN PENGEMBAN...</td>\n",
       "      <td>Penulis : SATIYAH</td>\n",
       "      <td>Dosen Pembimbing I : Dra. Hj. S. Anugrahini Ir...</td>\n",
       "      <td>Dosen Pembimbing II :Helmi Buyung Aulia,S,ST.S...</td>\n",
       "      <td>ABSTRAK\\r\\...</td>\n",
       "      <td>ABSTRACT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>analisis faktor-faktor yang berpengaruh terhad...</td>\n",
       "      <td>Penulis : Jailani</td>\n",
       "      <td>Dosen Pembimbing I : Hj. Evaliati amaniyah, SE...</td>\n",
       "      <td>Dosen Pembimbing II :Purnamawati, SE., M.Si</td>\n",
       "      <td>ABSTRAK\\r\\nTujuan penelitian ini adalah untuk ...</td>\n",
       "      <td>ABSTRACT\\r\\nThe objective of this research was...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Pengaruh Kompensasi Terhadap Kinerja Karywan p...</td>\n",
       "      <td>Penulis : agustin pratiwi</td>\n",
       "      <td>Dosen Pembimbing I : Drs.Ec. Mudji Kuswinarno....</td>\n",
       "      <td>Dosen Pembimbing II :Faidal. S.E, MM.</td>\n",
       "      <td>ABSTRAK \\r\\n\\r\\n\\tTujuan penelitian ini adalah...</td>\n",
       "      <td>ABSTRACT\\r\\n\\r\\n         The purpose of this s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PENGARUH STRUKTUR MODAL DAN LIKUIDITAS TERHADA...</td>\n",
       "      <td>Penulis : AHMAD ZAINI ALI</td>\n",
       "      <td>Dosen Pembimbing I : R. GATOT HERU PRANJOTO, S...</td>\n",
       "      <td>Dosen Pembimbing II :PURNAMAWATI, SE., MSi</td>\n",
       "      <td>Pendekatan penelitian yang digunakan dalam pen...</td>\n",
       "      <td>The research approach used in this study is a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>PENGARUH KUALITAS PELAYANAN TERHADAP KEPUASAN ...</td>\n",
       "      <td>Penulis : Annisa Lupita Rachmi Widhiastuti</td>\n",
       "      <td>Dosen Pembimbing I : Dr. H. Muh. Syarif. Drs E...</td>\n",
       "      <td>Dosen Pembimbing II :Yustina Chrismardani. S.S...</td>\n",
       "      <td>ABSTRAK\\r\\n\\r\\nTujuan penelitian ini adalah un...</td>\n",
       "      <td>ABSTRACT\\r\\nThe purpose of this study was to f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>PENGARUH PERILAKU KONSUMEN TERHADAP KEPUTUSAN ...</td>\n",
       "      <td>Penulis : Bany Azhar</td>\n",
       "      <td>Dosen Pembimbing I : dr.drs.Ec.H.Muh.Syarif,Msi</td>\n",
       "      <td>Dosen Pembimbing II :Hadi Purnomo, SE., MM</td>\n",
       "      <td>ABSTRAK\\r\\nTujuan penelitian ini adalah untuk ...</td>\n",
       "      <td>ABSTRACT\\r\\nThe purposes of this research (1) ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>PENGARUH PERSEPSI NILAI TERHADAP KEPUASAN PELA...</td>\n",
       "      <td>Penulis : Hasan Basri</td>\n",
       "      <td>Dosen Pembimbing I : Dr. Nurita Andriani, Ir., MM</td>\n",
       "      <td>Dosen Pembimbing II :Yustina Chrismardani, S.S...</td>\n",
       "      <td>Tujuan penelitian ini adalah untuk mengetahui ...</td>\n",
       "      <td>The purpose of this study was to find the effe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>PENGARUH HARGA DAN KUALITAS PRODUK TERHADAP KE...</td>\n",
       "      <td>Penulis : Irnita Agustin Putri</td>\n",
       "      <td>Dosen Pembimbing I : Dr. Drs. Ec H. Muh Syarif...</td>\n",
       "      <td>Dosen Pembimbing II :Hadi Purnomo, S.E., MM</td>\n",
       "      <td>ABSTRAK \\r\\nTujuan penelitian ini adalah (1) U...</td>\n",
       "      <td>\\tThe objective of this study are (1) To find ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Judul  \\\n",
       "0   Analisis Inovasi Dan Keunggulan Bersaing \\r\\nD...   \n",
       "1   Pengaruh Bauran Pemasaran Terhadap Keputusan P...   \n",
       "2   ANALISIS PORTOFOLIO YANG OPTIMAL DI BEI DENGAN...   \n",
       "3   PENGARUH KOMPETENSI DOSEN TERHADAP KINERJA DOS...   \n",
       "4   PENGARUH FAKTOR-FAKTOR PELATIHAN DAN PENGEMBAN...   \n",
       "5   analisis faktor-faktor yang berpengaruh terhad...   \n",
       "6   Pengaruh Kompensasi Terhadap Kinerja Karywan p...   \n",
       "7   PENGARUH STRUKTUR MODAL DAN LIKUIDITAS TERHADA...   \n",
       "8   PENGARUH KUALITAS PELAYANAN TERHADAP KEPUASAN ...   \n",
       "9   PENGARUH PERILAKU KONSUMEN TERHADAP KEPUTUSAN ...   \n",
       "10  PENGARUH PERSEPSI NILAI TERHADAP KEPUASAN PELA...   \n",
       "11  PENGARUH HARGA DAN KUALITAS PRODUK TERHADAP KE...   \n",
       "\n",
       "                                     Mahasiswa  \\\n",
       "0                   Penulis : Sandy Ardiansyah   \n",
       "1                       Penulis : Mahrus Saleh   \n",
       "2                     Penulis : Mira Dwiastuti   \n",
       "3                         Penulis : Aththaariq   \n",
       "4                            Penulis : SATIYAH   \n",
       "5                            Penulis : Jailani   \n",
       "6                    Penulis : agustin pratiwi   \n",
       "7                    Penulis : AHMAD ZAINI ALI   \n",
       "8   Penulis : Annisa Lupita Rachmi Widhiastuti   \n",
       "9                         Penulis : Bany Azhar   \n",
       "10                       Penulis : Hasan Basri   \n",
       "11              Penulis : Irnita Agustin Putri   \n",
       "\n",
       "                                            Dosbing_1  \\\n",
       "0   Dosen Pembimbing I : Dr. Ir. Nurita Andriani, MM.   \n",
       "1   Dosen Pembimbing I : Dr.H Pribanus Wantara, Dr...   \n",
       "2   Dosen Pembimbing I : Hj Evaliati Amaniyah, S.E...   \n",
       "3   Dosen Pembimbing I : Dr.RM Moch Wispandono,.S....   \n",
       "4   Dosen Pembimbing I : Dra. Hj. S. Anugrahini Ir...   \n",
       "5   Dosen Pembimbing I : Hj. Evaliati amaniyah, SE...   \n",
       "6   Dosen Pembimbing I : Drs.Ec. Mudji Kuswinarno....   \n",
       "7   Dosen Pembimbing I : R. GATOT HERU PRANJOTO, S...   \n",
       "8   Dosen Pembimbing I : Dr. H. Muh. Syarif. Drs E...   \n",
       "9     Dosen Pembimbing I : dr.drs.Ec.H.Muh.Syarif,Msi   \n",
       "10  Dosen Pembimbing I : Dr. Nurita Andriani, Ir., MM   \n",
       "11  Dosen Pembimbing I : Dr. Drs. Ec H. Muh Syarif...   \n",
       "\n",
       "                                            Dosbing_2  \\\n",
       "0         Dosen Pembimbing II :Suyono, S.E., M. S. M.   \n",
       "1          Dosen Pembimbing II :Hadi Purnomo, SE., MM   \n",
       "2         Dosen Pembimbing II :Echsan Gani, S.E, M.Si   \n",
       "3   Dosen Pembimbing II :Dr. Muhammad Alkirom Wild...   \n",
       "4   Dosen Pembimbing II :Helmi Buyung Aulia,S,ST.S...   \n",
       "5         Dosen Pembimbing II :Purnamawati, SE., M.Si   \n",
       "6               Dosen Pembimbing II :Faidal. S.E, MM.   \n",
       "7          Dosen Pembimbing II :PURNAMAWATI, SE., MSi   \n",
       "8   Dosen Pembimbing II :Yustina Chrismardani. S.S...   \n",
       "9          Dosen Pembimbing II :Hadi Purnomo, SE., MM   \n",
       "10  Dosen Pembimbing II :Yustina Chrismardani, S.S...   \n",
       "11        Dosen Pembimbing II :Hadi Purnomo, S.E., MM   \n",
       "\n",
       "                                         Abstrak_indo  \\\n",
       "0   ABSTRAK\\r\\n\\tTujuan penelitian ini adalah mend...   \n",
       "1   Objek penelitian ini adalah pembelian produk X...   \n",
       "2   Suatu keputusan investasi selalu berhubungan d...   \n",
       "3   Abstrak\\r\\n\\r\\nAththaariq, Pengaruh Kompetensi...   \n",
       "4                                       ABSTRAK\\r\\...   \n",
       "5   ABSTRAK\\r\\nTujuan penelitian ini adalah untuk ...   \n",
       "6   ABSTRAK \\r\\n\\r\\n\\tTujuan penelitian ini adalah...   \n",
       "7   Pendekatan penelitian yang digunakan dalam pen...   \n",
       "8   ABSTRAK\\r\\n\\r\\nTujuan penelitian ini adalah un...   \n",
       "9   ABSTRAK\\r\\nTujuan penelitian ini adalah untuk ...   \n",
       "10  Tujuan penelitian ini adalah untuk mengetahui ...   \n",
       "11  ABSTRAK \\r\\nTujuan penelitian ini adalah (1) U...   \n",
       "\n",
       "                                     Abstract_english  \n",
       "0   ABSTRACT\\r\\nThe purpose of this study is to de...  \n",
       "1   Object this research is consumer product of XL...  \n",
       "2   An investment decision is always associated wi...  \n",
       "3   Abstract\\r\\n\\r\\nThis study is aimed to analyze...  \n",
       "4                                         ABSTRACT...  \n",
       "5   ABSTRACT\\r\\nThe objective of this research was...  \n",
       "6   ABSTRACT\\r\\n\\r\\n         The purpose of this s...  \n",
       "7   The research approach used in this study is a ...  \n",
       "8   ABSTRACT\\r\\nThe purpose of this study was to f...  \n",
       "9   ABSTRACT\\r\\nThe purposes of this research (1) ...  \n",
       "10  The purpose of this study was to find the effe...  \n",
       "11  \\tThe objective of this study are (1) To find ...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data.csv')\n",
    "data.head(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12, 6)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Setelah kita read data, kita cek datanya dan kita cek banyaknya baris dan kolom ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Lalu kita cek jumlah missing value di tiap fiturnya"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Judul               0\n",
       "Mahasiswa           0\n",
       "Dosbing_1           0\n",
       "Dosbing_2           0\n",
       "Abstrak_indo        0\n",
       "Abstract_english    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(data.isnull())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">kode diatas untuk melakukan pengecekan missing value pada masing-masing fiturnya"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setelah dicek, dapat diketahui bahwa dari 12 dataset dan 6 fitur, tidak ditemukan missing value satu pun. <br>\n",
    "Dikarenakan tidak ada missing value yang ditemukan, maka tidak perlu dilakukan pemrosesan metode apapun untuk menangani missing value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <li> Melakukan Stopword"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dalam tahap ini, dataset yang telah dilakukan Pre-Processing data pada fitur \"Abstrak_indo\" akan di hapus kata-kata penghubungnya menggunakan bantuan library \"nltk\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading collection 'popular'\n",
      "[nltk_data]    | \n",
      "[nltk_data]    | Downloading package cmudict to\n",
      "[nltk_data]    |     C:\\Users\\nyamb\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package cmudict is already up-to-date!\n",
      "[nltk_data]    | Downloading package gazetteers to\n",
      "[nltk_data]    |     C:\\Users\\nyamb\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package gazetteers is already up-to-date!\n",
      "[nltk_data]    | Downloading package genesis to\n",
      "[nltk_data]    |     C:\\Users\\nyamb\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package genesis is already up-to-date!\n",
      "[nltk_data]    | Downloading package gutenberg to\n",
      "[nltk_data]    |     C:\\Users\\nyamb\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package gutenberg is already up-to-date!\n",
      "[nltk_data]    | Downloading package inaugural to\n",
      "[nltk_data]    |     C:\\Users\\nyamb\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package inaugural is already up-to-date!\n",
      "[nltk_data]    | Downloading package movie_reviews to\n",
      "[nltk_data]    |     C:\\Users\\nyamb\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package movie_reviews is already up-to-date!\n",
      "[nltk_data]    | Downloading package names to\n",
      "[nltk_data]    |     C:\\Users\\nyamb\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package names is already up-to-date!\n",
      "[nltk_data]    | Downloading package shakespeare to\n",
      "[nltk_data]    |     C:\\Users\\nyamb\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package shakespeare is already up-to-date!\n",
      "[nltk_data]    | Downloading package stopwords to\n",
      "[nltk_data]    |     C:\\Users\\nyamb\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package stopwords is already up-to-date!\n",
      "[nltk_data]    | Downloading package treebank to\n",
      "[nltk_data]    |     C:\\Users\\nyamb\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package twitter_samples to\n",
      "[nltk_data]    |     C:\\Users\\nyamb\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package twitter_samples is already up-to-date!\n",
      "[nltk_data]    | Downloading package omw to\n",
      "[nltk_data]    |     C:\\Users\\nyamb\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package omw is already up-to-date!\n",
      "[nltk_data]    | Downloading package omw-1.4 to\n",
      "[nltk_data]    |     C:\\Users\\nyamb\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet to\n",
      "[nltk_data]    |     C:\\Users\\nyamb\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet2021 to\n",
      "[nltk_data]    |     C:\\Users\\nyamb\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet2021 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet31 to\n",
      "[nltk_data]    |     C:\\Users\\nyamb\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet31 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet_ic to\n",
      "[nltk_data]    |     C:\\Users\\nyamb\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet_ic is already up-to-date!\n",
      "[nltk_data]    | Downloading package words to\n",
      "[nltk_data]    |     C:\\Users\\nyamb\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package words is already up-to-date!\n",
      "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
      "[nltk_data]    |     C:\\Users\\nyamb\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data]    | Downloading package punkt to\n",
      "[nltk_data]    |     C:\\Users\\nyamb\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package punkt is already up-to-date!\n",
      "[nltk_data]    | Downloading package snowball_data to\n",
      "[nltk_data]    |     C:\\Users\\nyamb\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package snowball_data is already up-to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]    |     C:\\Users\\nyamb\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n",
      "[nltk_data]    |       to-date!\n",
      "[nltk_data]    | \n",
      "[nltk_data]  Done downloading collection popular\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('popular')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "contents = data['Abstrak_indo']\n",
    "contents = contents.str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Script diatas berfungsi untuk membuat variabel \"contents\" yang berisi data \"Abstrak_indo\" lalu mengubah semua data menjadi lower case (dijadikan huruf kecil) agar sesuai dengan library stopword dari \"nltk\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stopping_word(contents):    \n",
    "    data_kata = []\n",
    "    stop_words = stopwords.words('english')\n",
    "    stop_words2 = stopwords.words('indonesian')\n",
    "    stop_words.extend(stop_words2)\n",
    "    jmlData = contents.shape \n",
    "    for i in range(jmlData[0]):\n",
    "        word_tokens = word_tokenize(contents[i])\n",
    "        # print(word_tokens)\n",
    "            \n",
    "        word_tokens_no_stopwords = [w for w in word_tokens if not w in stop_words]\n",
    "\n",
    "        special_char = \"+=`@_!#$%^&*()<>?/\\|}{~:;.[],1234567890‘’'\" + '\"“”●'\n",
    "        out_list = [''.join(x for x in string if not x in special_char) for string in word_tokens_no_stopwords]\n",
    "        # print('List after removal of special characters:', out_list)\n",
    "\n",
    "        while '' in out_list:\n",
    "            out_list.remove('')\n",
    "        data_kata.append(out_list)\n",
    "    return data_kata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Code diatas digunakan untuk melakukan stopword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_kata = stopping_word(contents)\n",
    "data['stop_kata'] = stop_kata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Lalu kita buat variabel \"stop_kata\" yang berisi data stopword dari variabel \"content\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     [abstrak, tujuan, penelitian, mendeskripsikan,...\n",
       "1     [objek, penelitian, pembelian, produk, xl, kec...\n",
       "2     [keputusan, investasi, berhubungan, keuntungan...\n",
       "3     [abstrak, aththaariq, pengaruh, kompetensi, do...\n",
       "4     [abstrak, satiyah, pengaruh, faktor-faktor, pe...\n",
       "5     [abstrak, tujuan, penelitian, pengaruh, variab...\n",
       "6     [abstrak, tujuan, penelitian, variabel, kompen...\n",
       "7     [pendekatan, penelitian, penelitian, pendekata...\n",
       "8     [abstrak, tujuan, penelitian, pengaruh, variab...\n",
       "9     [abstrak, tujuan, penelitian, pengaruh, perila...\n",
       "10    [tujuan, penelitian, pengaruh, variabel, perse...\n",
       "11    [abstrak, tujuan, penelitian, variabel, harga,...\n",
       "Name: stop_kata, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['stop_kata']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Lalu kita tampilkan semua hasil stopword dari setiap dokumen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <li> Term Frequency — Inverse Document Frequency (TF-IDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TF-IDF (Term Frequency Inverse Document Frequency) merupakan metode pembobotan dalam bentuk integrasi antar term frequency dengan inverse document frequency. Metode TF-IDF digunakan untuk memilih fitur sebagai hasil ringkasan, dengan penerapannya pada seleksi fitur bobot kata."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inti utama dari algoritma ini adalah melakukan perhitungan nilai TF dan nilai IDF dari sebuah setiap kata kunci terhadap masing-masing dokumen. Nilai TF dihitung dengan rumus TF = jumlah frekuensi kata terpilih / jumlah kata dan nilai IDF dihitung dengan rumus IDF = log(jumlah dokumen / jumlah frekuensi kata terpilih). Selanjutnya kedua hasil ini akan dikalikan sehingga menghasilkan TF-IDF. <br><br> TF-IDF dihitung dengan menggunakan persamaan seperti berikut.\n",
    "\n",
    "$$\n",
    "W_{i, j}=\\frac{n_{i, j}}{\\sum_{j=1}^{p} n_{j, i}} \\log _{2} \\frac{D}{d_{j}}\n",
    "$$\n",
    "\n",
    "Keterangan:\n",
    "\n",
    "$\n",
    "{W_{i, j}}\\quad\\quad\\>: \\text { pembobotan tf-idf untuk term ke-j pada dokumen ke-i } \\\\\n",
    "{n_{i, j}}\\quad\\quad\\>\\>: \\text { jumlah kemunculan term ke-j pada dokumen ke-i }\\\\\n",
    "{p} \\quad\\quad\\quad\\>\\>: \\text { banyaknya term yang terbentuk }\\\\\n",
    "{\\sum_{j=1}^{p} n_{j, i}}: \\text { jumlah kemunculan seluruh term pada dokumen ke-i }\\\\\n",
    "{d_{j}} \\quad\\quad\\quad: \\text { banyaknya dokumen yang mengandung term ke-j }\\\\\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Langkah pertama untuk melakukan proses TF-IDF tentunya import library yang akan kita gunakan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Mempersiapkan data yang sudah di stopword sebelumnya agar sesuai dengan format inputan dari salah satu library TF-IDF "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     abstrak tujuan penelitian mendeskripsikan inov...\n",
       "1     objek penelitian pembelian produk xl kecamatan...\n",
       "2     keputusan investasi berhubungan keuntungan ris...\n",
       "3     abstrak aththaariq pengaruh kompetensi dosen k...\n",
       "4     abstrak satiyah pengaruh faktor-faktor pelatih...\n",
       "5     abstrak tujuan penelitian pengaruh variabel cu...\n",
       "6     abstrak tujuan penelitian variabel kompensasi ...\n",
       "7     pendekatan penelitian penelitian pendekatan ku...\n",
       "8     abstrak tujuan penelitian pengaruh variabel ku...\n",
       "9     abstrak tujuan penelitian pengaruh perilaku ko...\n",
       "10    tujuan penelitian pengaruh variabel persepsi n...\n",
       "11    abstrak tujuan penelitian variabel harga kuali...\n",
       "Name: stop_kata_join, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['stop_kata_join'] = [' '.join(map(str, l)) for l in data['stop_kata']]\n",
    "data['stop_kata_join']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Menggunakan library CountVectorizer untuk mendapatkan value dari setiap kata yang muncul didalam sebuah dokumen, lalu memasukkannya dalam variabel \"bag\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "bag = vectorizer.fit_transform(data['stop_kata_join'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 0)\t1\n",
      "  (0, 382)\t1\n",
      "  (0, 259)\t3\n",
      "  (0, 201)\t1\n",
      "  (0, 119)\t5\n",
      "  (0, 152)\t5\n",
      "  (0, 30)\t5\n",
      "  (0, 155)\t3\n",
      "  (0, 254)\t3\n",
      "  (0, 72)\t1\n",
      "  (0, 239)\t3\n",
      "  (0, 319)\t3\n",
      "  (0, 175)\t3\n",
      "  (0, 53)\t1\n",
      "  (0, 169)\t1\n",
      "  (0, 257)\t1\n",
      "  (0, 94)\t1\n",
      "  (0, 366)\t2\n",
      "  (0, 268)\t1\n",
      "  (0, 50)\t4\n",
      "  (0, 396)\t1\n",
      "  (0, 235)\t1\n",
      "  (0, 266)\t1\n",
      "  (0, 76)\t1\n",
      "  (0, 10)\t1\n",
      "  :\t:\n",
      "  (11, 372)\t2\n",
      "  (11, 261)\t1\n",
      "  (11, 328)\t1\n",
      "  (11, 65)\t1\n",
      "  (11, 345)\t1\n",
      "  (11, 77)\t1\n",
      "  (11, 352)\t1\n",
      "  (11, 267)\t1\n",
      "  (11, 170)\t1\n",
      "  (11, 122)\t1\n",
      "  (11, 14)\t1\n",
      "  (11, 156)\t1\n",
      "  (11, 208)\t2\n",
      "  (11, 168)\t7\n",
      "  (11, 312)\t1\n",
      "  (11, 33)\t1\n",
      "  (11, 390)\t1\n",
      "  (11, 190)\t5\n",
      "  (11, 108)\t5\n",
      "  (11, 28)\t1\n",
      "  (11, 96)\t1\n",
      "  (11, 288)\t1\n",
      "  (11, 73)\t1\n",
      "  (11, 1)\t1\n",
      "  (11, 3)\t1 \n",
      "\n",
      "(12, 402)\n"
     ]
    }
   ],
   "source": [
    "print(bag, '\\n')\n",
    "print(bag.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variabel \"bag\" berisi total kemunculan kata dalam corpus yang muncul dalam setiap dokumen.  Jadi dari variabel ini dapat diketahui total kata yang diperoleh dari 12 dokumen adalah sebanyak 402 kata, yang dimana setiap dokumen akan menghitung term frequency-nya masing-masing dari daftar kata didalam corpus 12 data ini."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'abstrak': 0, 'tujuan': 382, 'penelitian': 259, 'mendeskripsikan': 201, 'inovasi': 119, 'keunggulan': 152, 'bersaing': 30, 'kinerja': 155, 'pemasaran': 254, 'diterapkannya': 72, 'optik': 239, 'reza': 319, 'lamongan': 175, 'deskriptif': 53, 'kualitatif': 169, 'pendekatan': 257, 'fenomenologi': 94, 'teknik': 366, 'pengumpulan': 268, 'data': 50, 'wawancara': 396, 'observasi': 235, 'penggunaan': 266, 'dokumen': 76, 'analisis': 10, 'reduction': 310, 'display': 68, 'conclusion': 44, 'drawing': 81, 'verification': 393, 'hasil': 106, 'perusahaan': 282, 'meningkatkan': 211, 'menerapkan': 203, 'volume': 395, 'omzet': 238, 'penjualan': 270, 'meningkat': 210, 'terbukti': 368, 'mengalami': 204, 'peningkatan': 269, 'produk': 292, 'ditawarkannya': 70, 'perbaikan': 272, 'pangsa': 243, 'pasarnya': 246, 'meluas': 193, 'daerah': 47, 'jawa': 128, 'timur': 376, 'kunci': 173, 'objek': 234, 'pembelian': 255, 'xl': 400, 'kecamatan': 139, 'bangkalan': 17, 'sampel': 327, 'konsumen': 165, 'meguji': 192, 'hipotesis': 110, 'regresi': 311, 'linier': 182, 'berganda': 26, 'memakai': 194, 'uji': 385, 'berdasar': 24, 'model': 221, 'sistematis': 346, 'simultan': 344, 'bauran': 21, 'harga': 105, 'promosi': 299, 'distribusi': 69, 'pengaruh': 262, 'signifikan': 340, 'keputusan': 147, 'bangkalansecara': 18, 'parsial': 244, 'variabel': 391, 'berpengaruh': 29, 'disimpulkan': 67, 'strategi': 355, 'segi': 333, 'investasi': 124, 'berhubungan': 27, 'keuntungan': 153, 'risiko': 320, 'investor': 125, 'rasional': 307, 'menginvestasikan': 207, 'dananya': 49, 'saham': 324, 'efisien': 86, 'return': 317, 'minimal': 216, 'aktif': 6, 'berdasarkan': 25, 'frekuensi': 100, 'perdagangan': 274, 'membagi': 195, 'dividen': 74, 'membentuk': 197, 'portofolio': 286, 'optimal': 240, 'perbedaan': 273, 'kandidat': 133, 'non': 232, 'diteliti': 71, 'nilai': 231, 'cut': 46, 'off': 237, 'point': 284, 'dibentuk': 59, 'excess': 91, 'returns': 318, 'beta': 34, 'erb': 90, 'ci': 43, 'diperoleh': 66, 'masuk': 191, 'perhitungan': 275, 'komposisi': 162, 'proporsi': 300, 'dana': 48, 'pt': 302, 'adaro': 2, 'energy': 88, 'tbk': 365, 'gudang': 104, 'garam': 102, 'hm': 111, 'sampoerna': 329, 'astra': 13, 'otopart': 241, 'multi': 228, 'bintang': 36, 'indonesia': 118, 'agro': 4, 'lestari': 177, 'goodyear': 103, 'indika': 114, 'united': 386, 'tractors': 380, 'pabrik': 242, 'kertas': 149, 'tjiwi': 378, 'kimia': 154, 'indofood': 116, 'sukses': 360, 'makmur': 186, 'international': 123, 'bank': 19, 'negara': 229, 'diatas': 57, 'metode': 215, 'indeks': 113, 'tunggal': 383, 'benar': 23, 'aktiva': 7, 'bebas': 22, 'expected': 92, 'aththaariq': 15, 'kompetensi': 161, 'dosen': 78, 'universitas': 387, 'trunojoyo': 381, 'madura': 185, 'dibawah': 58, 'bimbingan': 35, 'drrm': 82, 'moch': 219, 'wispandono': 399, 'se': 332, 'ms': 224, 'dr': 79, 'muhammad': 227, 'alkirom': 9, 'wildan': 397, 'msi': 225, 'bertujuan': 31, 'menganalisis': 206, 'pedagogik': 249, 'profesional': 295, 'sosial': 350, 'kepribadian': 144, 'terikat': 372, 'primer': 290, 'penyebaran': 271, 'kuesioner': 171, 'responden': 314, 'tersertifikasi': 374, 'pengambilan': 261, 'judgmental': 130, 'sampling': 328, 'koefisiensi': 159, 'determinasi': 54, 'dipengaruhi': 65, 'perubahan': 281, 'sisanya': 345, 'memiliki': 200, 'dominan': 77, 'signifikansi': 341, 'satiyah': 330, 'faktor': 93, 'pelatihan': 252, 'pengembangan': 263, 'produktivitas': 293, 'kerja': 148, 'dinas': 63, 'kelautan': 140, 'perikanan': 276, 'drahjsanugrahini': 80, 'irawati': 126, 'mm': 217, 'helmi': 109, 'buyung': 40, 'aulia': 16, 'stse': 357, 'mmt': 218, 'upaya': 388, 'mudah': 226, 'salah': 326, 'usaha': 389, 'program': 298, 'sumber': 361, 'daya': 51, 'manusia': 189, 'sdm': 331, 'dilaksanakan': 62, 'instansi': 120, 'tercapai': 369, 'kemampuan': 141, 'pegawai': 250, 'efektif': 85, 'pengembnagan': 264, 'diharapkan': 61, 'menyesuaikan': 213, 'kebutuhan': 138, 'sikap': 342, 'tingkah': 377, 'laku': 174, 'keterampilan': 151, 'pengetahuan': 265, 'sesuai': 339, 'tuntutan': 384, 'mendukung': 202, 'terciptanya': 370, 'suasana': 359, 'kondusif': 164, 'produktivitasi': 294, 'mengukur': 209, 'menganalisa': 205, 'hubungan': 112, 'peneliti': 258, 'observasional': 236, 'analitik': 11, 'pengamatan': 260, 'langsung': 176, 'kuisioner': 172, 'dianalisis': 56, 'populasi': 285, 'diolah': 64, 'spss': 351, 'versi': 394, 'statistik': 354, 'probality': 291, 'simple': 343, 'random': 305, 'kesimpulan': 150, 'individu': 115, 'jabatan': 127, 'motivasi': 222, 'partisipasi': 245, 'seleksi': 334, 'peserta': 283, 'instruktur': 121, 'kabupaten': 132, 'koefisien': 158, 'square': 352, 'fhitung': 95, 'ftabel': 101, 'pengujian': 267, 'thitung': 375, 'current': 45, 'ratio': 308, 'equity': 89, 'firm': 98, 'size': 347, 'leverage': 178, 'business': 39, 'risk': 321, 'kebijakan': 136, 'deviden': 55, 'manufaktur': 188, 'terdaftar': 371, 'bursa': 37, 'efek': 84, 'periode': 278, 'kuantitatif': 170, 'membagikan': 196, 'purposive': 303, 'instrumen': 122, 'asumsi': 14, 'klasik': 156, 'menguji': 208, 'businees': 38, 'dividend': 75, 'payout': 248, 'kompensasi': 160, 'finansial': 97, 'nonfinansial': 233, 'karyawan': 135, 'manakah': 187, 'membuktikan': 198, 'alat': 8, 'bantuan': 20, 'pos': 287, 'persero': 280, 'kantor': 134, 'cabang': 41, 'liquid': 183, 'penarikan': 256, 'purpossive': 304, 'statistical': 353, 'service': 336, 'solution': 349, 'duga': 83, 'rasio': 306, 'likuiditas': 180, 'struktur': 356, 'modal': 220, 'debt': 52, 'profitabilitas': 297, 'roe': 322, 'didapatkan': 60, 'lq': 184, 'kualitas': 168, 'pelayanan': 253, 'profesionalisme': 296, 'perilaku': 277, 'aksesibilitas': 5, 'fleksibilitas': 99, 'reliabilitas': 312, 'kepercayaan': 143, 'reputasi': 313, 'kredibilitas': 167, 'recovery': 309, 'serviscape': 337, 'kepuasan': 145, 'pasien': 247, 'rumah': 323, 'sakit': 325, 'terpadu': 373, 'surabaya': 362, 'besarnya': 33, 'servisecape': 338, 'kebudayaan': 137, 'pribadi': 289, 'psikologis': 301, 'susu': 363, 'cair': 42, 'merek': 214, 'indomilk': 117, 'swalayan': 364, 'tom': 379, 'jerry': 129, 'berusaha': 32, 'studi': 358, 'respondenteknik': 315, 'kepustakaan': 146, 'skala': 348, 'likert': 179, 'respondenuntuk': 316, 'validitas': 390, 'klasiksedangkan': 157, 'persepsi': 279, 'emosional': 87, 'kemudahan': 142, 'pelanggan': 251, 'variebel': 392, 'memilik': 199, 'terbesar': 367, 'sepeda': 335, 'motor': 223, 'yamaha': 401, 'new': 230, 'jupiter': 131, 'kota': 166, 'liniear': 181, 'menyebarkan': 212, 'hasilnya': 107, 'aplikasi': 12, 'komputer': 163, 'windows': 398, 'martabak': 190, 'hawaii': 108, 'berlandaskan': 28, 'filsafat': 96, 'positivisme': 288, 'ditetapkan': 73, 'accidental': 1, 'adjusted': 3}\n"
     ]
    }
   ],
   "source": [
    "print(vectorizer.vocabulary_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Diatas merupakan 402 kata yang ada dalam seluruh dokumen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Pemrosesan TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfTransformer(use_idf=True,norm='l2',smooth_idf=True)\n",
    "vect_abstrak=tfidf.fit_transform(bag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">buat variabel \"vect_abstrak\" yang berisi data dalam variabel \"bag\" yang telah dilakukan proses fit transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 396)\t0.06825539449816322\n",
      "  (0, 395)\t0.07947656181520893\n",
      "  (0, 393)\t0.07947656181520893\n",
      "  (0, 382)\t0.034935683350761415\n",
      "  (0, 376)\t0.07947656181520893\n",
      "  (0, 368)\t0.06825539449816322\n",
      "  (0, 366)\t0.07570302990096782\n",
      "  (0, 319)\t0.2384296854456268\n",
      "  (0, 310)\t0.07947656181520893\n",
      "  (0, 292)\t0.04907268226752964\n",
      "  (0, 282)\t0.060293849584575364\n",
      "  (0, 272)\t0.07947656181520893\n",
      "  (0, 270)\t0.07947656181520893\n",
      "  (0, 269)\t0.07947656181520893\n",
      "  (0, 268)\t0.060293849584575364\n",
      "  (0, 266)\t0.07947656181520893\n",
      "  (0, 259)\t0.08302441141780537\n",
      "  (0, 257)\t0.041111137353941785\n",
      "  (0, 254)\t0.20476618349448963\n",
      "  (0, 246)\t0.07947656181520893\n",
      "  (0, 243)\t0.07947656181520893\n",
      "  (0, 239)\t0.2384296854456268\n",
      "  (0, 238)\t0.07947656181520893\n",
      "  (0, 235)\t0.07947656181520893\n",
      "  (0, 211)\t0.060293849584575364\n",
      "  :\t:\n",
      "  (11, 147)\t0.22528652161584894\n",
      "  (11, 122)\t0.050198796552675076\n",
      "  (11, 110)\t0.0746091693912634\n",
      "  (11, 108)\t0.33084865079575393\n",
      "  (11, 106)\t0.02488546568490376\n",
      "  (11, 105)\t0.30119277931605043\n",
      "  (11, 96)\t0.06616973015915079\n",
      "  (11, 77)\t0.04085639929137948\n",
      "  (11, 73)\t0.06616973015915079\n",
      "  (11, 71)\t0.04505730432316979\n",
      "  (11, 65)\t0.050198796552675076\n",
      "  (11, 50)\t0.03422786294619935\n",
      "  (11, 33)\t0.0568273328978552\n",
      "  (11, 31)\t0.0568273328978552\n",
      "  (11, 29)\t0.14543185358347038\n",
      "  (11, 28)\t0.06616973015915079\n",
      "  (11, 26)\t0.029086370716694072\n",
      "  (11, 25)\t0.11191375408689509\n",
      "  (11, 22)\t0.04505730432316979\n",
      "  (11, 17)\t0.1865229234781585\n",
      "  (11, 14)\t0.050198796552675076\n",
      "  (11, 10)\t0.026890311068227406\n",
      "  (11, 3)\t0.06616973015915079\n",
      "  (11, 1)\t0.06616973015915079\n",
      "  (11, 0)\t0.03151400203008389\n"
     ]
    }
   ],
   "source": [
    "print(vect_abstrak)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Diatas ini merupakan daftar TF-IDF didalam setiap dokumen yang nilainya bukan 0 (terdapat kata yang muncul)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Menampilkan data hasil pemrosesan TD-IDF kedalam bentuk DataFrame agar lebih mudah dibaca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['abstrak', 'accidental', 'adaro', 'adjusted', 'agro',\n",
       "       'aksesibilitas', 'aktif', 'aktiva', 'alat', 'alkirom', 'analisis',\n",
       "       'analitik', 'aplikasi', 'astra', 'asumsi', 'aththaariq', 'aulia',\n",
       "       'bangkalan', 'bangkalansecara', 'bank', 'bantuan', 'bauran',\n",
       "       'bebas', 'benar', 'berdasar', 'berdasarkan', 'berganda',\n",
       "       'berhubungan', 'berlandaskan', 'berpengaruh', 'bersaing',\n",
       "       'bertujuan', 'berusaha', 'besarnya', 'beta', 'bimbingan',\n",
       "       'bintang', 'bursa', 'businees', 'business', 'buyung', 'cabang',\n",
       "       'cair', 'ci', 'conclusion', 'current', 'cut', 'daerah', 'dana',\n",
       "       'dananya', 'data', 'daya', 'debt', 'deskriptif', 'determinasi',\n",
       "       'deviden', 'dianalisis', 'diatas', 'dibawah', 'dibentuk',\n",
       "       'didapatkan', 'diharapkan', 'dilaksanakan', 'dinas', 'diolah',\n",
       "       'dipengaruhi', 'diperoleh', 'disimpulkan', 'display', 'distribusi',\n",
       "       'ditawarkannya', 'diteliti', 'diterapkannya', 'ditetapkan',\n",
       "       'dividen', 'dividend', 'dokumen', 'dominan', 'dosen', 'dr',\n",
       "       'drahjsanugrahini', 'drawing', 'drrm', 'duga', 'efek', 'efektif',\n",
       "       'efisien', 'emosional', 'energy', 'equity', 'erb', 'excess',\n",
       "       'expected', 'faktor', 'fenomenologi', 'fhitung', 'filsafat',\n",
       "       'finansial', 'firm', 'fleksibilitas', 'frekuensi', 'ftabel',\n",
       "       'garam', 'goodyear', 'gudang', 'harga', 'hasil', 'hasilnya',\n",
       "       'hawaii', 'helmi', 'hipotesis', 'hm', 'hubungan', 'indeks',\n",
       "       'indika', 'individu', 'indofood', 'indomilk', 'indonesia',\n",
       "       'inovasi', 'instansi', 'instruktur', 'instrumen', 'international',\n",
       "       'investasi', 'investor', 'irawati', 'jabatan', 'jawa', 'jerry',\n",
       "       'judgmental', 'jupiter', 'kabupaten', 'kandidat', 'kantor',\n",
       "       'karyawan', 'kebijakan', 'kebudayaan', 'kebutuhan', 'kecamatan',\n",
       "       'kelautan', 'kemampuan', 'kemudahan', 'kepercayaan', 'kepribadian',\n",
       "       'kepuasan', 'kepustakaan', 'keputusan', 'kerja', 'kertas',\n",
       "       'kesimpulan', 'keterampilan', 'keunggulan', 'keuntungan', 'kimia',\n",
       "       'kinerja', 'klasik', 'klasiksedangkan', 'koefisien', 'koefisiensi',\n",
       "       'kompensasi', 'kompetensi', 'komposisi', 'komputer', 'kondusif',\n",
       "       'konsumen', 'kota', 'kredibilitas', 'kualitas', 'kualitatif',\n",
       "       'kuantitatif', 'kuesioner', 'kuisioner', 'kunci', 'laku',\n",
       "       'lamongan', 'langsung', 'lestari', 'leverage', 'likert',\n",
       "       'likuiditas', 'liniear', 'linier', 'liquid', 'lq', 'madura',\n",
       "       'makmur', 'manakah', 'manufaktur', 'manusia', 'martabak', 'masuk',\n",
       "       'meguji', 'meluas', 'memakai', 'membagi', 'membagikan',\n",
       "       'membentuk', 'membuktikan', 'memilik', 'memiliki',\n",
       "       'mendeskripsikan', 'mendukung', 'menerapkan', 'mengalami',\n",
       "       'menganalisa', 'menganalisis', 'menginvestasikan', 'menguji',\n",
       "       'mengukur', 'meningkat', 'meningkatkan', 'menyebarkan',\n",
       "       'menyesuaikan', 'merek', 'metode', 'minimal', 'mm', 'mmt', 'moch',\n",
       "       'modal', 'model', 'motivasi', 'motor', 'ms', 'msi', 'mudah',\n",
       "       'muhammad', 'multi', 'negara', 'new', 'nilai', 'non',\n",
       "       'nonfinansial', 'objek', 'observasi', 'observasional', 'off',\n",
       "       'omzet', 'optik', 'optimal', 'otopart', 'pabrik', 'pangsa',\n",
       "       'parsial', 'partisipasi', 'pasarnya', 'pasien', 'payout',\n",
       "       'pedagogik', 'pegawai', 'pelanggan', 'pelatihan', 'pelayanan',\n",
       "       'pemasaran', 'pembelian', 'penarikan', 'pendekatan', 'peneliti',\n",
       "       'penelitian', 'pengamatan', 'pengambilan', 'pengaruh',\n",
       "       'pengembangan', 'pengembnagan', 'pengetahuan', 'penggunaan',\n",
       "       'pengujian', 'pengumpulan', 'peningkatan', 'penjualan',\n",
       "       'penyebaran', 'perbaikan', 'perbedaan', 'perdagangan',\n",
       "       'perhitungan', 'perikanan', 'perilaku', 'periode', 'persepsi',\n",
       "       'persero', 'perubahan', 'perusahaan', 'peserta', 'point',\n",
       "       'populasi', 'portofolio', 'pos', 'positivisme', 'pribadi',\n",
       "       'primer', 'probality', 'produk', 'produktivitas', 'produktivitasi',\n",
       "       'profesional', 'profesionalisme', 'profitabilitas', 'program',\n",
       "       'promosi', 'proporsi', 'psikologis', 'pt', 'purposive',\n",
       "       'purpossive', 'random', 'rasio', 'rasional', 'ratio', 'recovery',\n",
       "       'reduction', 'regresi', 'reliabilitas', 'reputasi', 'responden',\n",
       "       'respondenteknik', 'respondenuntuk', 'return', 'returns', 'reza',\n",
       "       'risiko', 'risk', 'roe', 'rumah', 'saham', 'sakit', 'salah',\n",
       "       'sampel', 'sampling', 'sampoerna', 'satiyah', 'sdm', 'se', 'segi',\n",
       "       'seleksi', 'sepeda', 'service', 'serviscape', 'servisecape',\n",
       "       'sesuai', 'signifikan', 'signifikansi', 'sikap', 'simple',\n",
       "       'simultan', 'sisanya', 'sistematis', 'size', 'skala', 'solution',\n",
       "       'sosial', 'spss', 'square', 'statistical', 'statistik', 'strategi',\n",
       "       'struktur', 'stse', 'studi', 'suasana', 'sukses', 'sumber',\n",
       "       'surabaya', 'susu', 'swalayan', 'tbk', 'teknik', 'terbesar',\n",
       "       'terbukti', 'tercapai', 'terciptanya', 'terdaftar', 'terikat',\n",
       "       'terpadu', 'tersertifikasi', 'thitung', 'timur', 'tingkah',\n",
       "       'tjiwi', 'tom', 'tractors', 'trunojoyo', 'tujuan', 'tunggal',\n",
       "       'tuntutan', 'uji', 'united', 'universitas', 'upaya', 'usaha',\n",
       "       'validitas', 'variabel', 'variebel', 'verification', 'versi',\n",
       "       'volume', 'wawancara', 'wildan', 'windows', 'wispandono', 'xl',\n",
       "       'yamaha'], dtype=object)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "term=vectorizer.get_feature_names_out()\n",
    "term"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "variabel \"term\" berisi daftar list kata didalam corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>abstrak</th>\n",
       "      <th>accidental</th>\n",
       "      <th>adaro</th>\n",
       "      <th>adjusted</th>\n",
       "      <th>agro</th>\n",
       "      <th>aksesibilitas</th>\n",
       "      <th>aktif</th>\n",
       "      <th>aktiva</th>\n",
       "      <th>alat</th>\n",
       "      <th>alkirom</th>\n",
       "      <th>...</th>\n",
       "      <th>variebel</th>\n",
       "      <th>verification</th>\n",
       "      <th>versi</th>\n",
       "      <th>volume</th>\n",
       "      <th>wawancara</th>\n",
       "      <th>wildan</th>\n",
       "      <th>windows</th>\n",
       "      <th>wispandono</th>\n",
       "      <th>xl</th>\n",
       "      <th>yamaha</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.037852</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.079477</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.079477</td>\n",
       "      <td>0.068255</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.346901</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.038308</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.038308</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.029062</td>\n",
       "      <td>0.038308</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.023769</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.037862</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.049908</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.049908</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.049908</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.018811</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.029964</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.033921</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 402 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    abstrak accidental     adaro adjusted      agro aksesibilitas     aktif  \\\n",
       "0  0.037852        0.0  0.000000      0.0  0.000000           0.0  0.000000   \n",
       "1  0.000000        0.0  0.000000      0.0  0.000000           0.0  0.000000   \n",
       "2  0.000000        0.0  0.038308      0.0  0.038308           0.0  0.029062   \n",
       "3  0.023769        0.0  0.000000      0.0  0.000000           0.0  0.037862   \n",
       "4  0.018811        0.0  0.000000      0.0  0.000000           0.0  0.029964   \n",
       "\n",
       "     aktiva alat   alkirom  ... variebel verification     versi    volume  \\\n",
       "0  0.000000  0.0  0.000000  ...      0.0     0.079477  0.000000  0.079477   \n",
       "1  0.000000  0.0  0.000000  ...      0.0     0.000000  0.000000  0.000000   \n",
       "2  0.038308  0.0  0.000000  ...      0.0     0.000000  0.000000  0.000000   \n",
       "3  0.000000  0.0  0.049908  ...      0.0     0.000000  0.000000  0.000000   \n",
       "4  0.000000  0.0  0.000000  ...      0.0     0.000000  0.033921  0.000000   \n",
       "\n",
       "  wawancara    wildan windows wispandono        xl yamaha  \n",
       "0  0.068255  0.000000     0.0   0.000000  0.000000    0.0  \n",
       "1  0.000000  0.000000     0.0   0.000000  0.346901    0.0  \n",
       "2  0.000000  0.000000     0.0   0.000000  0.000000    0.0  \n",
       "3  0.000000  0.049908     0.0   0.049908  0.000000    0.0  \n",
       "4  0.000000  0.000000     0.0   0.000000  0.000000    0.0  \n",
       "\n",
       "[5 rows x 402 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Tf_Idf =pd.DataFrame(data=vect_abstrak.toarray(), columns=[term])\n",
    "df_Tf_Idf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Menampilkan dataframe dari data yang telah diproses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12, 402)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Tf_Idf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dari hasil diatas dapat diketahui kata-kata yang tidak muncul didalam setiap dokumen memiliki nilai TF-IDF nol (0) sedangkan kata-kata yang muncul memiliki nilainya masing-masing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Penerapan LSA (Latent Semantic Analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSA dapat digunakan untuk mengekstrak topik yang tidak secara tersurat dapat dibaca dari sebuah kumpulan dokumen.<br>\n",
    "\n",
    "A = σ Σ U<br>\n",
    "\n",
    "Komputasi dasar yang ada di dalam LSA adalah perhitungan dua matriks yang berisi vektor eigen, umumnya dinotasikan sebagai σ dan U, serta satu matriks diagonal, umumnya dinotasikan sebagai Σ, yang kesemuanya mengkonstruksi sebuah matriks A, yaitu korpus atau kumpulan dokumen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Langkah awal kita import librarynya terlebih dahulu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Pemrosesan LSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsa_model = TruncatedSVD(n_components=12, algorithm='randomized', n_iter=10, random_state=42)\n",
    "lsa_top=lsa_model.fit_transform(vect_abstrak)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "kita lakukan proses LSA dengan <br>\n",
    "lalu buat variabel \"lsa_top\" berisi data \"vect_abstrak\" yang telah di lakukan proses fit transform ke lsa_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.48238828e-01  9.55335538e-03  3.52646005e-01  5.61366614e-01\n",
      "  -3.69232209e-01  1.51694087e-01 -4.93409831e-01 -3.61748911e-01\n",
      "  -4.75877690e-02  3.46457326e-02  1.68450208e-02  3.21647182e-02]\n",
      " [ 6.23594765e-01 -2.73744353e-01 -2.25230393e-01  2.97777806e-01\n",
      "  -2.29597198e-03  1.28558760e-01  1.41424750e-01  6.73462793e-02\n",
      "  -4.67343054e-02 -4.64358902e-01 -1.48414815e-01 -3.40417239e-01]\n",
      " [ 7.66471050e-02  1.42066816e-01  1.59717145e-01  1.65365775e-01\n",
      "   8.85075312e-01  2.61585648e-01 -2.57122178e-01 -1.13968608e-02\n",
      "   4.66081070e-03  8.16903441e-03 -5.33102335e-02  1.13725884e-02]\n",
      " [ 2.29729183e-01  5.04702806e-02  5.14388433e-01  1.47320480e-01\n",
      "  -2.89205424e-02 -4.21978371e-01 -1.28635939e-01  6.74943955e-01\n",
      "   7.50957397e-02 -3.42962770e-02  6.96699302e-04 -2.37421305e-02]\n",
      " [ 1.66403849e-01  1.11563144e-03  4.12183655e-01 -3.56036183e-01\n",
      "  -1.91028209e-01  7.20784802e-01  9.93314271e-02  2.42697751e-01\n",
      "  -2.24592410e-01 -1.18909504e-02  1.52319320e-02  6.69256481e-03]\n",
      " [ 4.37155796e-01  7.05443029e-01 -1.83111353e-01  1.03534960e-02\n",
      "  -2.65533019e-02  2.36105609e-02 -1.45693708e-02  1.73239921e-02\n",
      "  -9.31974232e-03  1.14438628e-02  4.97003191e-01 -1.69124407e-01]\n",
      " [ 1.91507384e-01  1.01170927e-01  5.40074641e-01  1.65436513e-01\n",
      "   1.15584202e-01 -1.55200271e-01  6.78383773e-01 -3.67055578e-01\n",
      "  -3.08286962e-05  3.40379847e-02  2.14251948e-02 -6.38045167e-03]\n",
      " [ 3.94116223e-01  7.34495365e-01 -1.36068455e-01 -1.91595506e-02\n",
      "  -1.30605934e-01  1.30469135e-02  2.99791891e-02  1.16809191e-02\n",
      "   4.85659237e-02  3.51229311e-02 -4.95599331e-01  1.37233213e-01]\n",
      " [ 4.10494968e-01 -4.90915274e-02  1.46399377e-01 -4.81797356e-01\n",
      "   7.68787955e-02 -3.78513155e-01 -2.77553543e-01 -2.70466228e-01\n",
      "  -5.09254113e-01 -5.65700194e-02 -5.99368864e-02 -1.00097842e-01]\n",
      " [ 5.69185259e-01 -2.94068998e-01 -2.18486348e-01  2.06514047e-01\n",
      "   2.62707153e-02  3.52153486e-02  1.04473733e-01  1.39323449e-01\n",
      "  -1.92501381e-01  6.49835269e-01 -4.05603687e-02 -7.69634493e-02]\n",
      " [ 5.09289511e-01 -1.81317916e-01  1.56328948e-01 -3.93166684e-01\n",
      "  -2.12433324e-02  3.03919899e-02 -1.65480133e-01 -1.87156607e-01\n",
      "   6.49906706e-01  1.25422633e-01 -2.83632811e-02 -1.61334946e-01]\n",
      " [ 7.60692329e-01 -2.50751754e-01 -1.26110347e-01 -5.74851067e-03\n",
      "   4.20852549e-02 -1.52388216e-02  2.76928626e-02  2.91815721e-03\n",
      "   3.74997074e-02 -1.86971534e-01  1.67653971e-01  5.24673838e-01]]\n",
      "(12, 12)\n"
     ]
    }
   ],
   "source": [
    "print(lsa_top)\n",
    "print(lsa_top.shape)  # (no_of_doc*no_of_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 0 :\n",
      "Topic  0  :  14.823882835793098\n",
      "Topic  1  :  0.9553355376840661\n",
      "Topic  2  :  35.26460049303363\n",
      "Topic  3  :  56.13666137200081\n",
      "Topic  4  :  -36.923220925848845\n",
      "Topic  5  :  15.16940873730705\n",
      "Topic  6  :  -49.34098313962991\n",
      "Topic  7  :  -36.17489112553782\n",
      "Topic  8  :  -4.7587768964035035\n",
      "Topic  9  :  3.4645732600801527\n",
      "Topic  10  :  1.6845020786928928\n",
      "Topic  11  :  3.2164718197986977\n"
     ]
    }
   ],
   "source": [
    "l=lsa_top[0]\n",
    "print(\"Document 0 :\")\n",
    "for i,topic in enumerate(l):\n",
    "    print(\"Topic \",i,\" : \",topic*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12, 402)\n",
      "[[ 3.91283910e-02  2.27676870e-02  1.32811756e-03 ...  5.18607943e-03\n",
      "   9.78495012e-02  5.61981559e-02]\n",
      " [ 7.69515288e-03 -1.24775084e-02  4.09267657e-03 ...  1.89423009e-03\n",
      "  -7.14126814e-02 -3.32638158e-02]\n",
      " [ 3.55312713e-02 -7.66745961e-03  5.62190109e-03 ...  2.35887588e-02\n",
      "  -7.17916689e-02  3.50418993e-02]\n",
      " ...\n",
      " [ 1.83838296e-02 -1.77523862e-02  4.49037756e-04 ... -2.45607342e-03\n",
      "  -2.31143296e-01  4.39040532e-02]\n",
      " [ 3.67721205e-02  2.00744049e-02 -3.69547533e-03 ...  6.29197997e-05\n",
      "  -9.31649102e-02 -1.25208197e-02]\n",
      " [ 1.35747005e-02  7.19701936e-02  9.03136660e-04 ... -2.45638293e-03\n",
      "  -2.44805453e-01 -8.15904199e-02]]\n"
     ]
    }
   ],
   "source": [
    "print(lsa_model.components_.shape) # (no_of_topics*no_of_words)\n",
    "print(lsa_model.components_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0: \n",
      "variabel produk pembelian uji kualitas keputusan penelitian harga ratio bangkalan berpengaruh konsumen signifikan merek hawaii martabak pengaruh distribusi kecamatan xl \n",
      "\n",
      "Topic 1: \n",
      "ratio current equity profitabilitas perusahaan debt roe return firm leverage risk size businees dividend payout bursa efek terdaftar indonesia signifikan \n",
      "\n",
      "Topic 2: \n",
      "kompensasi kompetensi kinerja finansial dosen langsung faktor kerja produktivitas karyawan bersaing inovasi keunggulan pelatihan pegawai pengembangan nilai nonfinansial pedagogik pt \n",
      "\n",
      "Topic 3: \n",
      "bersaing inovasi keunggulan kinerja pemasaran pembelian lamongan optik reza keputusan kompensasi data distribusi kecamatan xl kompetensi produk jawa mengalami konsumen \n",
      "\n",
      "Topic 4: \n",
      "tbk pt portofolio saham optimal risiko return astra excess kandidat beta kompensasi benar cut energy indeks off perhitungan point tunggal \n",
      "\n",
      "Topic 5: \n",
      "kerja produktivitas pelatihan faktor pegawai pengembangan dinas kelautan perikanan tbk pt portofolio bangkalan saham hubungan instansi seleksi meningkat bersaing inovasi \n",
      "\n",
      "Topic 6: \n",
      "kompensasi finansial langsung karyawan nonfinansial pembelian fhitung signifikan keputusan distribusi kecamatan xl bangkalan cabang kantor persero pos konsumen alat linier \n",
      "\n",
      "Topic 7: \n",
      "kompetensi dosen pedagogik sosial kepribadian madura profesional trunojoyo universitas kerja produktivitas pelatihan se pegawai pengembangan pembelian dinas kelautan perikanan keputusan \n",
      "\n",
      "Topic 8: \n",
      "pelanggan jupiter kota motor new sepeda yamaha harga emosional kemudahan persepsi kualitas merek terbesar membuktikan produk metode kompetensi bangkalan responden \n",
      "\n",
      "Topic 9: \n",
      "cair indomilk susu merek perilaku konsumen psikologis kebudayaan pribadi sosial jerry swalayan tom pendekatan dominan berusaha kepustakaan klasiksedangkan likert respondenteknik \n",
      "\n",
      "Topic 10: \n",
      "firm leverage risk size return businees dividend payout deviden manufaktur periode hawaii martabak berdasarkan menguji berpengaruh kualitas klasik business kebijakan \n",
      "\n",
      "Topic 11: \n",
      "hawaii martabak kualitas harga profitabilitas terikat variabel menguji debt roe accidental adjusted berlandaskan ditetapkan filsafat positivisme berdasarkan bertujuan validitas pembelian \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nyamb\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# most important words for each topic\n",
    "vocab = vectorizer.get_feature_names()\n",
    "\n",
    "for i, comp in enumerate(lsa_model.components_):\n",
    "    vocab_comp = zip(vocab, comp)\n",
    "    sorted_words = sorted(vocab_comp, key= lambda x:x[1], reverse=True)[:20]\n",
    "    print(\"Topic \"+str(i)+\": \")\n",
    "    for t in sorted_words:\n",
    "        print(t[0],end=\" \")\n",
    "    print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d2f50273f46bff6fba023c2dfce614ab0d56fe9941f21ee4698635d2ffd9f27a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
